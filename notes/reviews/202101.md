RDF NeuroPheno classifications

Notes 20210123

- Very ephys centered ... crossover to imaging techniques, staining?
- p8 Fig3 ... the definitions for the predicates?

- p5 Fig1 ... what is the knowledge gain of the B) images? if there is none, please remove it

- p6 ... is the NPO onl for modeling as p6 exists? provide a definition of what this paper understands as modeling

- is this the full set of terms? if not how will it be expanded? e.g. does hasProteinExpression include stainings?

- p8 Fig3 ... is this the full model of molecular phenotypes

- Data and code availability is very hard to read


Notes 20210124

- p12 ... not yet transparent how the minimal list of set of molex/morph is chosen to define a neuron

is the aim of NPO aimed only at mammalian neurons? if not include other data and examples as well to show the approach works there too and how.

what do they ant to show/achieve with this paper?
... search of terms and comparison across databases and identifying techniques provided competent personal feeds the database.

what are the results supposed to show? that the defined classes enable search? where is the gold standard showing it finds what is supposed to be found based on the used data?

this approach depends on proper curation of data to classes
... where is the description of this process if people are supposed to use it on their own?

p15 ... what is the point of the result? cool, a search result can be interpreted but how does this lead back to the introduced POV(?)? strange assumption unless I miss something.

ok ... so is this whole approach there to compare across phenotypes? is there no other approach that has tried this? if yes where and why is the new one better; if no, where is this statement?

Neuron Phenotype Ont ... describing complex phenotypes of Neurons

p20 F3 ... "include ID of data it describes" ... is that true with respect to the DATA

p19 ... is the definition of CUT and EBT the same as above??

is this reproducible? where is the description how this ontology was created from the basic sources.

this paper leaves me very confused after the first read...


Notes 20210129

- in general the curation of the basis of this data set is not well described enough from my point of view.
- the dataset is a secondary reference; how can the original data be accessed, verified and referenced? mistakes happen, which is ok, but there needs to be a mechanism to easily backcheck whats in the data set, how it got there and from where.

    The approach is great, but it is a secondary source; when various people of various backgrounds try to adopt it and add to it mistakes are bound to happen. Easy backchecking should be part of the definition in this case to verify any result of a search.

p4 "Anyone who has attempted to read through multiple articles, each with their
own proposal for classifying cell types within a region understands the difficulties in trying to
reconcile the different schemes, even when they are based on limited numbers of data
dimensions."
.. true, how is this approach better, if the layer of reconciliation is opaque.


who has stewardship of the resource; how will iterations of the resource be referenced and will previous iterations be accessible?

p4 and further; not sure if the way taxonomy is used is correct. "Here, we show how the NPO can be used to express taxonomies proposed by different research groups using modern techniques, enable comparisons between them, and enable queries with commonly used neuron types from the literature"


p5 fig1B ... I do not see how this figure is helpful or relevant

p8 fig3 ... where can the full set of predicates actually be found and reviewed? NPOKB is registered with bioportal (https://bioportal.bioontology.org/ontologies/NPOKB) but there not even all the predicates can be found that are referenced in this figure e.g. hasEpigeneticPhenotype

p9 ... "In this way, as proposed originally by Hamilton et al., (2012), it is easy to generate a human readable list of neurons from a given species or brain region and to compare across complex phenotypes." ... I think this is a good and valid approach.


Notes 01.02.2021

The process how data has to treated to be subjected to a search usind the reported owl restrictiobs is either missing or lacking a prominent description. Further the raw and transformed data used as basis for the competence queries is missing or obscurely described an placed.

Putting the core of the paper, the owl npo.ttl file in a side branch of a github repository is prone to removal. Get a doi for this essential data and put a version number on the file to keep it properly findable, accessible and reusable.


Meeting w JG

General Topic of the paper:
The authors describe the development of an ontology that aims at resolving neuronal cell type classifications across approaches and resources.
As a proof of concept the authors show the combination of phenotype information from three resources that use very different approches. To this end, the Web Ontology Language (OWL), has been employed to define a searchable set of "Neuron types" and combine it with already existing Ontology resources to create a searchable but easily expandable data source. Using, "competency queries" the authors also show that the database can then be actually used to extract specific phenotypic information and thus identifying similar neurons described in different resources.

Major issues:
	* The process of data import is completely opague. For someone to actually use the NPO this is not helpful and actually contradicts the FAIR principles. For example on  page 8: 2nd sentence the authors state that only those  "... protein, peptides and small molecules, that are thought to define the class" enter the database. This is an important decision. Who decides this? This may evolve over time. Such decisions made by the authors should be more clearly stated and justified.
	* The dataset is a secondary reference; how can the original data be accessed, verified and referenced? Easy backchecking should be part of the definition in this case to verify any result of a search.
	* NPO is publicly available but who has stewardship over the database? 
	* The authors explicitely state that the current paper is a proof-of-concept but they should at least hint at and discuss with other parts of neurosciences they are not covering, or how they should be integrated.
	* The distinction between Common Usage Types and Evidence Based Types is central to the paper but it should be introduced by actually describing figure 1 A 
	* The general approach of modelling a cell type as a "bag of phenotypes" is valid. Fig 2 illustrates the concept, but the link to the actual NPO terms is not described. "Species" or "Brain region" are general terms that can be used to categorize Neuron Pheontypes, but  they are not actual NPO terms as the figure caption suggests. Further the relation between Figure 2 and Table 1 is unclear; not all terms in Figure 2 map directly to Table 1 and a further description is not provided in the text.
	* figure 3 shows the predicates used in NPO, are they original NPO inventions or are they reused from other ontologies? How did you decide which predicates need to be defined and which could be reused from other ontologies? Further these terms cannot be found in the reference npo.ttl file; how are these terms actually tied into the NPO definition.
	* 


Minor issues:
	* Several info from supplement to main text, e.g. the information about the NIF Ontology 
	* https://github.com/SciCrunch/NIF-Ontology/blob/neurons/ttl/npo.ttl
	* page 6, 2nd paragraph: the term "disjointness axioms" falls out of the sky but may not be familiar to people not acquainted with OWL semantics.
	* page 6, bottom; Is there a reference for NeuronLang?
	* figure 3: predicate "hasExpressionPhenotypeDeterminedByEphysAndPharmacology": two comments: (1) is it wise to combine Ephys and Pharmacology in the same predicate? (2) inconsistency in using "ephys" abbreviated and spelled out in other predicates. 
	* Figure 4 caption: "Neuron Lang" and "Neuro DM" are sometimes referenced as "Neuro Lang" and "Neuron DM".
	* 

Notes 20210207

## Introductory statement
We find this approach intriguing, relevant and apt to address the complexity of neuronal classification. We spent time to investigate the technologies and tools described, which are not common or familiar to the majority of neuroscientists. The paper abstract generalizes its audience or at least does not specify a target audience and from this point of view we tried to review the paper from the viewpoint of a non-specialised neuroscientist trying to apply a presented method. We read the paper, supplemental materials, read into the github pages for both SciCrunch/NIF-Ontology (neuron branch) and tgbugs/pyontutils:neurondm and tried to re-create the ontology using webprotege.standford.edu and neurondm in a conda environment. All of the comments are meant to provide incentives to open the paper for a broader audience which we feel is not the case in the current form. If the intention of the paper was to target a specific audience only, this should be stated clearly in the abstract and the introduction.

Even tough we invested a reasonable amount of time to setup and try to recreate at least the basis database for the reported competence queries, we were not able to recreate it with the information provided. A description of the transformation of raw CUTs data to an NPO based graph as well as the raw data for EBTs and how to transform this data using neuromd was missing completely making it impossible to test the queries reported in this manuscript. It seems, that the ttl files found at the NIF-Ontology neurons branch on github in the https://github.com/SciCrunch/NIF-Ontology/tree/neurons/ttl/generated/neurons directory contains the ttl files, but the raw data from which these files were created could not be identified.


## Major review points

It is our opinion that even if this can be a feasible approach to topple a complex problem, unless the process to generate the database (the owl file), transparantly describe the process how the owl file is created, to a broader audiance that is not yet familiar with semantic web technologie, this will remain an academic exercise and not reach neuroscientists that have the means to add to this database.

The turtle file, which is at the core of this publication resides in a branch of a specific github repo. Since openn source projects on platforms like github are by design dynamic this is a dead link in the making. This file should have a version number, that is also referenced in the paper and most importantly should have its own doi that is prominently placed in this paper.

Further to enable neuroscientists that are not yet familiar with semantic web tec, there should be a laymans introduction either in the paper or in a referenced documentation, also with a version number. Otherwise this will not be of interest to the general public and not be fair

We propose a major rewrite of the data and code availability section to include a comprehensible description how the NPOKB is created, can be extended and by which criteria the current version has been constructed.

Provide a detailed example workflow how new classes are added to the NPOKB. This has to contain all tools involved. This has to contain the criteria by which new classes are defined.

In the paper it is unclear whether it publishes "just"" a new "data model" for neuron phenotype classification or also a kernel data as well to grow from (neuron example data in pyontutils/neurondm/models).

The reviewers could not clearly identify the raw EBT data used for the competence queries and were not able to check whether the results reported where even part of the original data.


### Ontology description problems

The described NPO "data model" is supposed to be an ontology that can be used to create a queryable graph. The currently presented NPO imports various terms from other, existing ontologies. Table 1 provides a general overview of which ontologies have been used to populate the NPO "data model". A detailed description which existing ontologies are imported is not obvious in the sense that it is not described by which criteria terms were imported from existing ontologies and when new terms were included in the presented NPO. Providing these criteria would also help future extension of this ontology.
As an example: it remains opaque to the reader in Figure 3 (Page 6) to which ontology which predicate belongs and how this particular predicate tree has been constructed. When loading the v1.0 ("2020-08-03") npo.ttl file to webprotege and searching for the "hasMolecularPhenotype" predicate, the resulting predicate is an interlex term (http://uri.interlex.org/tgbugs/uris/readable/hasMolecularPhenotype). A search on the interlex platform itself for hasMolecularPhenotype does not return any result. When reviewing Table 1 (Page 4), "Molecular" terms are supposed to be imported from the NCBI Gene, CHEBI or Protein Ontology ontologies. This example shows, that the construction process of the NPO is not transparently described in the provided figures, tables or texts.

While the predicates as e.g. "hasMolecularPhenotype" seem crucial to the construction of the NPO "data model", they are not part of the provided `npo.ttl` file and it also not obviously described, where these terms are stored. It seems, that they all are defined via and are part of the interlex ontology but neither is this ontology specifically linked nor is it obviously described how the link to the npo ontology was defined.

As a more detailed example that the published process is hard to follow and can not easily be verified:
Page 5, text paragraph, page 6, figure 3: the text paragraph states, that terms not used in version v1.0 are greyed out in Figure 3. When loading npo.ttl to webprotege and searching for the terms in Figure 3, while e.g. "hasNeurotransmitterPhenotype" returns a search result, the terms "hasRNAExpressionPhenotype" and "hasEpigeneticPhenotype" that should be included in the NPO cannot be found. Since the used Interlex ontology terms are not provided in the manuscript (neither link nor version), it cannot be checked, which predicates are actually available and used for the publication of v1.0 of the NPO ontology.


### Problem distinction between "data model" and database content
The way the paper handles "data model" and database content is very confusing. A reader is lead to believe, that the "data model", the ontology, also contains data which is not the case.

We could not find a definition and description of the term NPOKB and its difference to the NPO term.

On page 9 in the first sentence of the section refers to the NPO/NPOKB. What is the difference between NPO and the NPOKB? Is the NPOKB supposed to contain data transformed by the NPO model? If yes, the link provided does not contain any NPOKB data which I suppose is actually found in the neuronmd python code itself.

The paper does not describe how terms for the data model were specified. Are the "criteria to identify CUT" used to identify new terms for the ontology or are they used to identify neurons from the literature and then transformed using the existing NPO


### Data extraction criteria issue
The process how and by which criteria the data from the three referenced publications was extracted is opaque.
  - CUT identification criteria are described in the supplemental materials
  - we could not find any criteria how EBTs are mapped to the NPO.

Raw data for CUTs has been provided but it is unclear how these data were produced and how they were used to create classes in the range of the NPO. Further the CUTs data transformed using the NPO were not provided or could not be easily found. If the tsv files were used to load via NeuroMD to populate a graph, this is conjecture by the reviewers but a definite description of this process could not be found in the manuscript.

The reviewers assume, that the neurodm software package contains the code to transform raw data from the three referenced data sources (Markram et. al. 2015, Paul et. al. 2017 and Allen Cell Types database), but could not identify the raw data source files for this transformation in the manuscript or the linked software neurodm on github.

Provide a figure a) highlighting the difference between "data model" (ontology) and the data transformed to this data model; b) a description of the workflow how data is extracted from published sources and transformed using the "data model" to an accessible and queryable data source. This has to contain all essential tools required to handle this workflow.


## Minor review points

- Is the NPOKB supposedly the full "database"? Please clarify this point or rather define somewhere what the "full" ontology is supposed to be.
- Test if the database can actually be easily recreated; if not, it is not FAIR.
- using the term NPOKB implies that there is a published knowledge base containing data using the published "data model". Is this the case?

The target audience of the paper is unclear: is it a prototype ontology for people developing ontologies or is it for neurobiologists that want to use a different resource for neuron type investigation. If it is the first, this should be stated in the abstract. If this is the second

The current examples include data from ephys sources (three referenced papers) from mammals. Outline how data from other neuroscientific fields e.g. imaging and other model organisms e.g. invertebrates can be incorporated and about which issues in this respect the authors are aware of in this respect. This should demonstrate, that the approach is not specific to electrophysiology by to the full field of neuroscience as the article seems to aspire to.

Give an outlook how this approach should continue; by whom and how will it be expanded; by whom and how should this approach be used in the future.


- Page 9, Data and code availability: The whole section reads erratic and unstructured. Paragraphs often read like redundant information since it is not specified for which purpose links in different paragraphs are provided.
- Page 9, Data and code availability: Link consistency ... links are sometimes provided plain in text, sometimes as hidden URLs. Provide links in a consistent, easy to parse manor.

- Page 9, Data and code availability: The text references the NPO as v1.0; the reference points to a github tag containing the tag "npo-1.0" referencing a commit in the `neurons` branch. The file referenced via the provided link to the npo.ttl in the neurons branch of this particular tag is identical to the above described file in the `neurons` branch
  - The linked file does not contain a version number; the only version information available in this file is the entry `owl:versionInfo "2020-08-03" ;`. Users should be easily able to trace back a used file to its origin. Either the file itself should contain the version number stated in the paper, or the github tag name should contain the version info data and the version number in the paper should also contain this version information.

- Page 9, Data and code availability: The first paragraph does not specify that the link to the npo.ttl file points to a dynamic file and will be updated in the future.
- Page 9, Data and code availability: The description of the link
https://raw.githubusercontent.com/SciCrunch/NIF-Ontology/npo-1.0/ttl/npo.ttl
does not specify that this is a github tag pointing to the specific v1.0 release and also does not state, that it points on the `neurons` branch; a clarification would help to understand both links only currently point to the exact same file.
