RDF NeuroPheno classifications

Notes 20210123

- Very ephys centered ... crossover to imaging techniques, staining?
- p8 Fig3 ... the definitions for the predicates?

- p5 Fig1 ... what is the knowledge gain of the B) images? if there is none, please remove it

- p6 ... is the NPO onl for modeling as p6 exists? provide a definition of what this paper understands as modeling

- is this the full set of terms? if not how will it be expanded? e.g. does hasProteinExpression include stainings?

- p8 Fig3 ... is this the full model of molecular phenotypes

- Data and code availability is very hard to read


Notes 20210124

- p12 ... not yet transparent how the minimal list of set of molex/morph is chosen to define a neuron

is the aim of NPO aimed only at mammalian neurons? if not include other data and examples as well to show the approach works there too and how.

what do they ant to show/achieve with this paper?
... search of terms and comparison across databases and identifying techniques provided competent personal feeds the database.

what are the results supposed to show? that the defined classes enable search? where is the gold standard showing it finds what is supposed to be found based on the used data?

this approach depends on proper curation of data to classes
... where is the description of this process if people are supposed to use it on their own?

p15 ... what is the point of the result? cool, a search result can be interpreted but how does this lead back to the introduced POV(?)? strange assumption unless I miss something.

ok ... so is this whole approach there to compare across phenotypes? is there no other approach that has tried this? if yes where and why is the new one better; if no, where is this statement?

Neuron Phenotype Ont ... describing complex phenotypes of Neurons

p20 F3 ... "include ID of data it describes" ... is that true with respect to the DATA

p19 ... is the definition of CUT and EBT the same as above??

is this reproducible? where is the description how this ontology was created from the basic sources.

this paper leaves me very confused after the first read...


Notes 20210129

- in general the curation of the basis of this data set is not well described enough from my point of view.
- the dataset is a secondary reference; how can the original data be accessed, verified and referenced? mistakes happen, which is ok, but there needs to be a mechanism to easily backcheck whats in the data set, how it got there and from where.

    The approach is great, but it is a secondary source; when various people of various backgrounds try to adopt it and add to it mistakes are bound to happen. Easy backchecking should be part of the definition in this case to verify any result of a search.

p4 "Anyone who has attempted to read through multiple articles, each with their
own proposal for classifying cell types within a region understands the difficulties in trying to
reconcile the different schemes, even when they are based on limited numbers of data
dimensions."
.. true, how is this approach better, if the layer of reconciliation is opaque.


who has stewardship of the resource; how will iterations of the resource be referenced and will previous iterations be accessible?

p4 and further; not sure if the way taxonomy is used is correct. "Here, we show how the NPO can be used to express taxonomies proposed by different research groups using modern techniques, enable comparisons between them, and enable queries with commonly used neuron types from the literature"


p5 fig1B ... I do not see how this figure is helpful or relevant

p8 fig3 ... where can the full set of predicates actually be found and reviewed? NPOKB is registered with bioportal (https://bioportal.bioontology.org/ontologies/NPOKB) but there not even all the predicates can be found that are referenced in this figure e.g. hasEpigeneticPhenotype

p9 ... "In this way, as proposed originally by Hamilton et al., (2012), it is easy to generate a human readable list of neurons from a given species or brain region and to compare across complex phenotypes." ... I think this is a good and valid approach.


Notes 01.02.2021

The process how data has to treated to be subjected to a search usind the reported owl restrictiobs is either missing or lacking a prominent description. Further the raw and transformed data used as basis for the competence queries is missing or obscurely described an placed.

Putting the core of the paper, the owl npo.ttl file in a side branch of a github repository is prone to removal. Get a doi for this essential data and put a version number on the file to keep it properly findable, accessible and reusable.


Meeting w JG

General Topic of the paper:
The authors describe the development of an ontology that aims at resolving neuronal cell type classifications across approaches and resources.
As a proof of concept the authors show the combination of phenotype information from three resources that use very different approches. To this end, the Web Ontology Language (OWL), has been employed to define a searchable set of "Neuron types" and combine it with already existing Ontology resources to create a searchable but easily expandable data source. Using, "competency queries" the authors also show that the database can then be actually used to extract specific phenotypic information and thus identifying similar neurons described in different resources.

Major issues:
	* x The process of data import is completely opaque. For someone to actually use the NPO this is not helpful and actually contradicts the FAIR principles. For example on  page 8: 2nd sentence the authors state that only those  "... protein, peptides and small molecules, that are thought to define the class" enter the database. This is an important decision. Who decides this? This may evolve over time. Such decisions made by the authors should be more clearly stated and justified.
	* x The dataset is a secondary reference; how can the original data be accessed, verified and referenced? Easy backchecking should be part of the definition in this case to verify any result of a search.
	* x NPO is publicly available but who has stewardship over the database? 
	* x The authors explicitly state that the current paper is a proof-of-concept but they should at least hint at and discuss with other parts of neurosciences they are not covering, or how they should be integrated.
	* x The distinction between Common Usage Types and Evidence Based Types is central to the paper but it should be introduced by actually describing figure 1 A 
	* x The general approach of modelling a cell type as a "bag of phenotypes" is valid. Fig 2 illustrates the concept, but the link to the actual NPO terms is not described. "Species" or "Brain region" are general terms that can be used to categorize Neuron Phenotypes, but they are not actual NPO terms as the figure caption suggests. Further the relation between Figure 2 and Table 1 is unclear; not all terms in Figure 2 map directly to Table 1 and a further description is not provided in the text.
	* x figure 3 shows the predicates used in NPO, are they original NPO inventions or are they reused from other ontologies? How did you decide which predicates need to be defined and which could be reused from other ontologies? Further these terms cannot be found in the reference npo.ttl file; how are these terms actually tied into the NPO definition.
	* 


Minor issues:
	* Several info from supplement to main text, e.g. the information about the NIF Ontology 
	* https://github.com/SciCrunch/NIF-Ontology/blob/neurons/ttl/npo.ttl
	* page 6, 2nd paragraph: the term "disjointness axioms" falls out of the sky but may not be familiar to people not acquainted with OWL semantics.
	* page 6, bottom; Is there a reference for NeuronLang?
	* figure 3: predicate "hasExpressionPhenotypeDeterminedByEphysAndPharmacology": two comments: (1) is it wise to combine Ephys and Pharmacology in the same predicate? (2) inconsistency in using "ephys" abbreviated and spelled out in other predicates. 
	* Figure 4 caption: "Neuron Lang" and "Neuro DM" are sometimes referenced as "Neuro Lang" and "Neuron DM".
	* 

Notes 20210207

## Introductory statement
We find this approach intriguing, relevant and apt to address the complexity of neuronal classification. We spent time to investigate the technologies and tools described, which are not common or familiar to the majority of neuroscientists. The paper abstract generalizes its audience or at least does not specify a target audience and from this point of view we tried to review the paper from the viewpoint of a non-specialised neuroscientist trying to apply a presented method. We read the paper, supplemental materials, read into the github pages for both SciCrunch/NIF-Ontology (neuron branch) and tgbugs/pyontutils:neurondm and tried to re-create the ontology using webprotege.standford.edu and neurondm in a conda environment. All of the comments are meant to provide incentives to open the paper for a broader audience which we feel is not the case in the current form. If the intention of the paper was to target a specific audience only, this should be stated clearly in the abstract and the introduction.

Even tough we invested a reasonable amount of time to setup and try to recreate at least the basis database for the reported competence queries, we were not able to recreate it with the information provided. A description of the transformation of raw CUTs data to an NPO based graph as well as the raw data for EBTs and how to transform this data using neuromd was missing completely making it impossible to test the queries reported in this manuscript. It seems, that the ttl files found at the NIF-Ontology neurons branch on github in the https://github.com/SciCrunch/NIF-Ontology/tree/neurons/ttl/generated/neurons directory contains the ttl files, but the raw data from which these files were created could not be identified.


## Major review points

It is our opinion that even if this can be a feasible approach to topple a complex problem, unless the process to generate the database (the owl file), transparently describe the process how the owl file is created, to a broader audience that is not yet familiar with semantic web technology, this will remain an academic exercise and not reach neuroscientists that have the means to add to this database.

The turtle file, which is at the core of this publication resides in a branch of a specific github repo. Since openn source projects on platforms like github are by design dynamic this is a dead link in the making. This file should have a version number, that is also referenced in the paper and most importantly should have its own doi that is prominently placed in this paper.

Further to enable neuroscientists that are not yet familiar with semantic web tec, there should be a laymans introduction either in the paper or in a referenced documentation, also with a version number. Otherwise this will not be of interest to the general public and not be fair

We propose a major rewrite of the data and code availability section to include a comprehensible description how the NPOKB is created, can be extended and by which criteria the current version has been constructed.

Provide a detailed example workflow how new classes are added to the NPOKB. This has to contain all tools involved. This has to contain the criteria by which new classes are defined.

In the paper it is unclear whether it publishes "just"" a new "data model" for neuron phenotype classification or also a kernel data as well to grow from (neuron example data in pyontutils/neurondm/models).

The reviewers could not clearly identify the raw EBT data used for the competence queries and were not able to check whether the results reported where even part of the original data.


### Ontology description problems

The described NPO "data model" is supposed to be an ontology that can be used to create a queryable graph database. The currently presented NPO imports various terms from other, existing ontologies. Table 1 provides a general overview of which ontologies have been used to populate the NPO "data model". A detailed description which existing ontologies are imported is not obvious in the sense that it is not described by which criteria terms were imported from existing ontologies and when new terms were included in the presented NPO. Providing these criteria would also help future extension of this ontology.
As an example: it remains opaque to the reader in Figure 3 (Page 6) to which ontology which predicate belongs and how this particular predicate tree has been constructed. When loading the v1.0 ("2020-08-03") npo.ttl file to webprotege and searching for the "hasMolecularPhenotype" predicate, the resulting predicate is an interlex term (http://uri.interlex.org/tgbugs/uris/readable/hasMolecularPhenotype). A search on the interlex platform itself for hasMolecularPhenotype does not return any result. When reviewing Table 1 (Page 4), "Molecular" terms are supposed to be imported from the NCBI Gene, CHEBI or Protein Ontology ontologies. This example shows, that the construction process of the NPO is not transparently described in the provided figures, tables or texts.

While the predicates as e.g. "hasMolecularPhenotype" seem crucial to the construction of the NPO "data model", they are not part of the provided `npo.ttl` file and it also not obviously described, where these terms are stored. It seems, that they all are defined via and are part of the interlex ontology but neither is this ontology specifically linked nor is it obviously described how the link to the npo ontology was defined.

As a more detailed example that the published process is hard to follow and can not easily be verified:
Page 5, text paragraph, page 6, figure 3: the text paragraph states, that terms not used in version v1.0 are greyed out in Figure 3. When loading npo.ttl to webprotege and searching for the terms in Figure 3, while e.g. "hasNeurotransmitterPhenotype" returns a search result, the terms "hasRNAExpressionPhenotype" and "hasEpigeneticPhenotype" that should be included in the NPO cannot be found. Since the used Interlex ontology terms are not provided in the manuscript (neither link nor version), it cannot be checked, which predicates are actually available and used for the publication of v1.0 of the NPO ontology.


### Problem distinction between "data model" and database content
The way the paper handles "data model" and database content is very confusing. A reader is lead to believe, that the "data model", the ontology, also contains data which is not the case.

- We could not find a definition and description of the term NPOKB and its difference to the NPO term.

- On page 9 in the first sentence of the section refers to the NPO/NPOKB. What is the difference between NPO and the NPOKB? Is the NPOKB supposed to contain data transformed by the NPO model? If yes, the link provided does not contain any NPOKB data which I suppose is actually found in the neuronmd python code itself.

The paper does not describe how terms for the "data model" were specified. Are the "criteria to identify CUT" used to identify new terms for the ontology or are they used to identify neurons from the literature and then transformed using the existing NPO?


### Data extraction criteria issue
The process how and by which criteria the data from the three referenced publications was extracted is opaque.
  - CUT identification criteria are described in the supplemental materials
  - we could not find any criteria how EBTs are mapped to the NPO.

Raw data for CUTs has been provided but it is unclear how these data were produced and how they were used to create classes in the range of the NPO. Further the CUTs data transformed using the NPO were not provided or could not be easily found. If the tsv files were used to load via NeuroMD to populate a graph, this is conjecture by the reviewers but a definite description of this process could not be found in the manuscript.

The reviewers assume, that the neurodm software package contains the code to transform raw data from the three referenced data sources (Markram et. al. 2015, Paul et. al. 2017 and Allen Cell Types database), but could not identify the raw data source files for this transformation in the manuscript or the linked software neurodm on github.

Provide a figure a) highlighting the difference between "data model" (ontology) and the data transformed to this data model; b) a description of the workflow how data is extracted from published sources and transformed using the "data model" to an accessible and queryable data source. This has to contain all essential tools required to handle this workflow.


## Minor review points

- Is the NPOKB supposedly the full "database"? Please clarify this point or rather define somewhere what the "full" ontology is supposed to be.
- Test if the database can actually be easily recreated; if not, it is not FAIR.
- using the term NPOKB implies that there is a published knowledge base containing data using the published "data model". Is this the case?

The target audience of the paper is unclear: is it a prototype ontology for people developing ontologies or is it for neurobiologists that want to use a different resource for neuron type investigation. If it is the first, this should be stated in the abstract. If this is the second

The current examples include data from ephys sources (three referenced papers) from mammals. Outline how data from other neuroscientific fields e.g. imaging and other model organisms e.g. invertebrates can be incorporated and about which issues in this respect the authors are aware of in this respect. This should demonstrate, that the approach is not specific to electrophysiology by to the full field of neuroscience as the article seems to aspire to.

Give an outlook how this approach should continue; by whom and how will it be expanded; by whom and how should this approach be used in the future.

- Page 9, Data and code availability: The whole section reads erratic and unstructured. Paragraphs often read like redundant information since it is not specified for which purpose links in different paragraphs are provided.
- Page 9, Data and code availability: Link consistency ... links are sometimes provided plain in text, sometimes as hidden URLs. Provide links in a consistent, easy to parse manor.

- Page 9, Data and code availability: The text references the NPO as v1.0; the reference points to a github tag containing the tag "npo-1.0" referencing a commit in the `neurons` branch. The file referenced via the provided link to the npo.ttl in the neurons branch of this particular tag is identical to the above described file in the `neurons` branch
  - The linked file does not contain a version number; the only version information available in this file is the entry `owl:versionInfo "2020-08-03" ;`. Users should be easily able to trace back a used file to its origin. Either the file itself should contain the version number stated in the paper, or the github tag name should contain the version info data and the version number in the paper should also contain this version information.

- Page 9, Data and code availability: The first paragraph does not specify that the link to the npo.ttl file points to a dynamic file and will be updated in the future.
- Page 9, Data and code availability: The description of the link
https://raw.githubusercontent.com/SciCrunch/NIF-Ontology/npo-1.0/ttl/npo.ttl
does not specify that this is a github tag pointing to the specific v1.0 release and also does not state, that it points on the `neurons` branch; a clarification would help to understand both links only currently point to the exact same file.


# Clean review notes

## Introductory statement

### Paper topic
The authors describe the development of an ontology aiming at resolving neuronal cell type classifications across approaches and resources.
As a proof of concept the authors use the Web Ontology Language (OWL) together with already existing ontologies to define an easily extensible ontology specific for different neuronal phenotypes (NPO). They specify two different main sources of data to be described and unified by the NPO, CUT (common usage types) and the EBT (evidence based types). They use the reported Neuron Phenotype Ontology to transform data from three different published cortical data sets into a searchable graph database. Finally using "competency queries" the authors also show that the database can then be actually used to extract specific phenotypic information and thus identifying similar neurons described in different resources and phenotypes reported in the literature.


### Reviewers general statements

The reviewers find this approach intriguing, relevant and apt to address the complexity of neuronal classification. Further we find the approach to infer not-described small molecule contents by comparison to similar neuron phenotypes for follow up studies as "pretty cool" and definitely an approach to follow up and invest time in.

We spent time to investigate the technologies and tools described, which are not common or familiar to the majority of neuroscientists. The paper abstract generalizes its audience or at least does not specify a target audience and from this point of view we tried to review the paper from the viewpoint of a non-specialised neuroscientist trying to apply a presented method. We read the paper, supplemental materials, read into the github pages for both "SciCrunch/NIF-Ontology" (neuron branch) and "tgbugs/pyontutils:neurondm" and tried to re-create the ontology using "webprotege.standford.edu" and "neurondm" in a conda environment. Most of the comments are meant to provide incentives to open the paper for a broader audience which we feel is not the case in the current form. If the intention of the paper was to target a specific audience only, this should be stated clearly in the abstract and the introduction.


## Major review points

### Figure and content issues
- The distinction between Common Usage Types and Evidence Based Types is central to the paper but it should be introduced by actually describing Figure 1 A.

- The general approach of modelling a cell type as a "bag of phenotypes" is valid. Fig 2 illustrates the concept, but the link to the actual NPO terms is not described. "Species" or "Brain region" are general terms that can be used to categorize Neuron Phenotypes, but they are not actual NPO terms as the figure caption suggests. Further the relation between Figure 2 and Table 1 is unclear; not all terms in Figure 2 map directly to Table 1 and a further description is not provided in the text.


### Ontology description problems

The described NPO "data model" is supposed to be an ontology that can be applied to curated raw data to create a queryable graph database. The currently presented NPO imports various terms from other existing ontologies. Table 1 provides a general overview of which ontologies have been used in the NPO "data model". A detailed description which existing ontologies are imported is not obvious in the sense that it is not described by which criteria terms were imported from existing ontologies and when new terms were newly defined for the presented NPO. Providing these criteria would also help future extension of this ontology.
As an example: it remains opaque to the reader in Figure 3 (Page 6) to which ontology which predicate belongs and how this particular predicate tree has been constructed. When loading the v1.0 ("2020-08-03") "npo.ttl" file to webprotege and searching for the "hasMolecularPhenotype" predicate, the resulting predicate is an interlex term (http://uri.interlex.org/tgbugs/uris/readable/hasMolecularPhenotype). A search on the interlex platform itself for hasMolecularPhenotype does not return any result. When reviewing Table 1 (Page 4), "Molecular" terms are supposed to be imported from the NCBI Gene, CHEBI or Protein Ontology ontologies. This example shows that the construction process of the NPO is not transparently described in the provided figures, tables or texts.

While the predicates as e.g. "hasMolecularPhenotype" seem crucial to the construction of the NPO "data model", they are not part of the provided "npo.ttl" file and it also not obviously described, where these terms are stored. It seems, that they all are defined via and are part of the Interlex ontology but neither is this ontology specifically linked nor is it obviously described how the link to the NPO was defined.

As a more detailed example that the published process is hard to follow and can not easily be verified:
Page 5, text paragraph, page 6, figure 3: the text paragraph states, that terms not used in version v1.0 are greyed out in Figure 3. When loading "npo.ttl" to webprotege and searching for the terms in Figure 3, while e.g. "hasNeurotransmitterPhenotype" returns a search result, the terms "hasRNAExpressionPhenotype" and "hasEpigeneticPhenotype" that should be included in the NPO cannot be found. Since the used Interlex ontology terms are not provided in the manuscript (neither link nor version), it cannot be verified, which predicates are available and used for the publication of v1.0 of the NPO ontology.


### "data model" and database content distinction issue

The way the manuscript handles "data model" and database content is ambiguous. Reviewing the "neuron" branch of the "SciCrunch/NIF-Ontology" github repository it appears, that the content of the "database" is contained in the "generated/neurons" subdirectory. To the reader it is not clear in which relationship "general" ontology terms stand to these specific generated neuron files. Are these generated files, which the reviewers assume are part of the queryable data, also part of the ontology?
Along these lines, the manuscript does not provide a definition and description of the term NPOKB and its difference to the NPO term.
The manuscript should provide an ample description how "data model" and database content relate to each other.
The manuscript also does not describe how terms for the "data model" were specified. Are the "criteria to identify CUT" in the supplemental materials used to identify new terms for the ontology or are they used to identify neurons from the literature and then transformed using the existing NPO?


### Data extraction criteria issue

The process how and by which criteria the data from the three referenced publications was extracted is opaque.

For example on  page 8: 2nd sentence the authors state that only those  "... protein, peptides and small molecules, that are thought to define the class" enter the database. This is an important decision. Who decides this? This may evolve over time. Such decisions made by the authors should be more clearly stated and justified.

Raw data for CUTs has been provided but it is unclear how these data were produced and how they were used to create classes in the range of the NPO. Further the CUTs data transformed using the NPO were not provided or could not be easily found. If the tsv files were used to load via "neurondm" to populate a graph, this is conjecture by the reviewers but a definite description of this process could not be found in the manuscript.

Criteria to extract raw data from "EBTs" and how they are mapped via the NPO could not be found. The reviewers assume that the "neurondm" software package contains the code to transform raw data from the three referenced EBT data sources (Markram et. al. 2015, Paul et. al. 2017 and Allen Cell Types database), but could not identify the raw data source files for this transformation in the manuscript or the linked software "neurondm" on github.

Provide a figure a) highlighting the difference between "data model" (ontology) and the data transformed to this data model into a searchable graph; b) a description of the workflow how data is extracted from published sources and transformed using the "data model" to an accessible and queryable data source. This has to contain all essential tools required to handle this workflow.


### Raw data issues

Even tough we invested a reasonable amount of time to setup and try to recreate the database for the reported competence queries, we were not able to recreate them with the information provided from the raw data. A description of the transformation of raw CUTs data to an NPO based graph as well as the raw data for EBTs and how to transform this data using "neuromd" was missing, making it impossible to test the queries reported in this manuscript.

It seems that the "ttl" files found at the github "NIF-Ontology" "neurons" branch in the https://github.com/SciCrunch/NIF-Ontology/tree/neurons/ttl/generated/neurons directory include the EBT ttl files, but the raw data from which these files were created could not be identified.

The reviewers could not clearly identify the raw EBT data used for the competence queries and were not able to check whether the results reported where part of the original data.

In general the reported data set is a secondary reference; how can the original data be accessed, verified and referenced? Easy backchecking should be part of the definition in this case to verify any result of a search.


### General criticism of the Data and Code Availability section

We propose a major rewrite of the "Data and Code Availability" section to include a comprehensible description how the NPOKB is created, can be extended and by which criteria the current version has been constructed. The whole section reads erratic and unstructured. Paragraphs often read like redundant information since it is not specified for which purpose links in different paragraphs are provided.

Further provide a detailed example workflow how new classes are added to the NPOKB. This has to contain all tools involved. This has to contain the criteria by which new classes are defined.


### Data and Code Availability issues

The ontology files, which are at the core of this publication, reside in a branch of a provided github repo. Since open source projects on platforms like github are by design dynamic this is a dead link in the making. The core "npo.ttl" file should contain a version number, that is also referenced in the paper. Most importantly the full published ontology reported by this manuscript should be provided via its own DOI as well since the content of both the github repository in general and the "neuron" branch in particular will change in the future; the reported status should be not only be available via a github tag, but also via its own DOI which we have not been able to find in the Data and code availability section.


### Target audience issue

It is our opinion that even if this can be a feasible approach to topple a complex problem, unless the process to generate the database (ontology files) transparently describe the process how the ontology files are created, to a broader audience that is not yet familiar with semantic web technology, this will remain an academic exercise and not reach neuroscientists that have the means to easily use and add to this datasource.
Further to enable neuroscientists that are not yet familiar with semantic web tec, there should be a laymans introduction either in the paper or in a referenced documentation, also with a version number. Otherwise this will not be of interest to the general public and not be fair
The target audience of the paper is unclear: is it a prototype ontology for people developing ontologies or is it for neurobiologists that want to use a different resource for neuron type investigation. If it is the first, this should be stated in the abstract.


### Outlook issue

- The authors explicitly state that the current paper is a proof-of-concept but they should at least hint at and discuss with other parts of neurosciences they are not covering, or how they should be integrated.

- The current examples include data from mammalian cortical sources of three referenced papers. Outline how data from other neuroscientific fields e.g. imaging and other model organisms e.g. invertebrates can be incorporated and which issues the authors are aware of in this respect. This should demonstrate that the approach is not specific to the reported datasets but to the full field of neuroscience as the article is aspiring to. The authors explicitly state that the current paper is a proof-of-concept but they should at least hint at and discuss with other parts of neurosciences they are not covering, or how they should be integrated.

- Along these lines give an outlook how this approach should continue; by whom and how will it be expanded; by whom and how should this approach be used in the future; who has stewardship over a potential resulting resource.


## Minor review points

- As a general comment, this manuscript has not been sufficiently proofread making it besides its demanding content unnecessarily hard to review. In multiple sections it is hard to read, contains redundant wording e.g. page 19 "... phenotypes themselves lend themselves ..." and inconsistent naming link usage schemes (see issues below).

- Page 6, 2nd paragraph: the term "disjointness axioms" falls out of the sky but may not be familiar to people not acquainted with OWL semantics.

- Page 6, bottom paragraph: Is there a reference for NeuronLang?

- Inconsistent software naming: "Neuron Lang" and "Neuron DM" are sometimes referenced as "Neuro Lang" or "Neuro DM" e.g. in Figure 4 caption ("Neuro Lang") v.s. occurrence in previous issue.

- Figure 3: predicate "hasExpressionPhenotypeDeterminedByEphysAndPharmacology": two comments: (1) is it wise to combine Ephys and Pharmacology in the same predicate? (2) inconsistency in using "ephys" abbreviated and spelled out in other predicates.

- Page 9, Data and code availability: The section shows link representation consistency. Links are sometimes provided plain in text, sometimes as hidden URLs. Provide links in a consistent, easy to parse manor.

- Page 9, Data and code availability: The text references the NPO as v1.0; the reference points to a github tag containing the tag "npo-1.0" referencing a commit in the `neurons` branch. The file referenced via the provided link to the "npo.ttl" in the neurons branch of this particular tag is identical to the above described file in the `neurons` branch. The linked file does not contain a version number; the only version information available in this file is the entry `owl:versionInfo "2020-08-03" ;`. Users should be easily able to trace back a used file to its origin. Either the file itself should contain the version number stated in the paper, or the github tag name should contain the version info data and the version number in the paper should also contain this version information.

- Page 9, Data and code availability: The first paragraph does not specify that the link to the "npo.ttl" file points to a dynamic file and will be updated in the future.

- Page 9, Data and code availability: The description of the link https://raw.githubusercontent.com/SciCrunch/NIF-Ontology/npo-1.0/ttl/npo.ttl does not specify that this is a github tag pointing to the specific v1.0 release and also does not state, that it points on the `neurons` branch; a clarification would help to understand both links only currently point to the exact same file.

# Meeting notes JG, 20210208

# The Neuron Phenotype Ontology: A FAIR Approach to Proposing and Classifying Neuronal Types
The authors describe the development of an ontology aiming at resolving neuronal cell type classifications across approaches and resources. This addresses an important neuroscientific problem of linking information from different sources. For example the link between morphology and physiology is often not made simply because the work is done in different labs that use different methods. Bringing the knowledge together is a difficult task which is further complicated when different terms are used in different communities. At this point ontologies can fill the gap and help to join research results across communities.
As a proof of concept the authors use the Web Ontology Language (OWL) together with already existing ontologies to define an easily extensible ontology specifically adapted to different neuronal phenotypes (NPO). They specify two different main sources of neuron data to be described and unified by the NPO, CUT (common usage types) and the EBT (evidence based types). They use the reported Neuron Phenotype Ontology to transform data from three different published cortical data sets into a searchable graph database. Finally using "competency queries" the authors also show that the database can then be used to extract specific phenotypic information and thus identifying similar neurons described in different resources and phenotypes reported in the literature.

We find this approach intriguing, relevant and apt to address the complexity of neuronal classification. Further, we find the approach to infer not-described small molecule contents or other phenotypic criteria by comparison to similar neuron phenotypes for follow up studies as pretty exciting and definitely an approach to follow up and invest time in.

We spent time to investigate the technologies and described tools which the majority of neuroscientists are probably not familiar with. The manuscript abstract does not specify a target audience and therefore we tried to review the paper from the viewpoint of a non-specialised neuroscientist trying to apply a presented method. We attempted to re-create the ontology using "webprotege.standford.edu" and "neurondm" in a conda environment by following the information provided in the paper, the supplemental materials, and the github pages for both "SciCrunch/NIF-Ontology" (neuron branch) and "tgbugs/pyontutils:neurondm". Most of our comments are meant to provide incentives to open the paper for a broader audience which we feel is not the case in the current form. If the intention of the paper was to target a specific audience only, this should be stated clearly in the abstract and the introduction.

Taken together we think that the paper addresses an important issue and uses a valid approach to solve the problem. We do however see several major points that need to be addressed. We will detail these in the following paragraphs.


## Major points

### Target audience
What is the target audience of this manuscript? The general neuroscientist unfamiliar with the concepts described and applied in this work requires a laymans introduction either in the paper or in a referenced documentation.
If this is not the target audience, the scope of this manuscript might be limited to experts. This should be made clear already in the abstract. 

### Ontology description is not sufficient
Please provide more/detailed information. The described NPO "data model" is supposed to be an ontology that can be applied to curated raw data to create a queryable graph database. The currently presented NPO imports various terms from other existing ontologies. Table 1 provides a general overview over the ontologies used in the NPO "data model". A detailed description which existing ontologies are imported is not obvious in the sense that it is not described by which criteria terms were imported from existing ontologies and when new terms were defined for the NPO. Providing these criteria would also help future extension of this ontology.
As an example: it remains unclear to the reader in Figure 3 (Page 6) to which ontology which predicate belongs and how this particular predicate tree has been constructed. When loading the v1.0 ("2020-08-03") "npo.ttl" file into webprotege and searching for the "hasMolecularPhenotype" predicate, the resulting predicate is an interlex term (http://uri.interlex.org/tgbugs/uris/readable/hasMolecularPhenotype). A search on the interlex platform itself for hasMolecularPhenotype does not return any result. When reviewing Table 1 (Page 4), "Molecular" terms are supposed to be imported from the NCBI Gene, CHEBI or Protein Ontology ontologies.

While predicates such as "hasMolecularPhenotype" seem crucial to the construction of the NPO "data model", they are not part of the provided "npo.ttl" file and it also not obviously described, where these terms are stored. It seems that they all are defined via the Interlex ontology but neither is this ontology specifically linked nor is it obviously described how the link to the NPO was defined.

As a more detailed example that the published process is hard to follow and can not easily be verified: Page 5, text paragraph, page 6, Figure 3: the text paragraph states, that terms not used in version v1.0 are greyed out in Figure 3. When loading "npo.ttl" to webprotege and searching for the terms in Figure 3, while e.g. "hasNeurotransmitterPhenotype" returns a search result, the terms "hasRNAExpressionPhenotype" and "hasEpigeneticPhenotype" that should be included in the NPO cannot be found. Since the used Interlex ontology terms are not provided in the manuscript (neither link nor version), it cannot be verified, which predicates are available and used for the the v1.0 NPO ontology publication.

### Distinction between "ontology", "data model", "database", and "knowledge base" is unclear.
Clearly defining and applying these terms would help the naive reader to assess the paper.
The way the manuscript handles "data model" and "database" content (raw data transformed to a queryable form) is ambiguous. Reviewing the "neuron" branch of the "SciCrunch/NIF-Ontology" github repository it appears that the content of the "database" is contained in the "generated/neurons" subdirectory. To the reader it is not clear in which relationship "general" ontology terms stand to these specific generated neuron files. Are these generated files, which the reviewers assume are part of the queryable data, also part of the ontology?
Along these lines, the manuscript does not provide a definition and description of the term NPOKB and its difference to the NPO term.
The manuscript should provide an ample description how "data model" and database content relate to each other.
The manuscript also does not describe how terms for the "data model" were specified. Are the "criteria to identify CUT" in the supplemental materials used to identify new terms for the ontology or are they used to identify neurons from the literature and then transformed using the existing NPO?

Is there a way to illustrate and compare the vocabulary on the one hand and resulting searchable graph containing the data on the other hand? Illustrating this transformation would give the reader a much more intuitive understanding of the general ideas and concepts.

### The process of how and by which criteria the data from the three referenced publications was extracted is opaque.
For example on page 8, 2nd sentence the authors state that only those  "... protein, peptides and small molecules, that are thought to define the class ..." enter the database. This is an important decision. Who decides this? This may evolve over time. Such decisions made by the authors should be more clearly stated and justified.

Raw data for CUTs has been provided but it is unclear how these data were produced and how they were used to create classes in the range of the NPO. Further the CUTs data transformed using the NPO were not provided or could not be easily found. We assume that the provided tsv files together with the "neurondm" software was used to populate a graph, but this process is not described in the manuscript.

Criteria to extract raw data from "EBTs" and how they are mapped via the NPO could not be found. We assume that the "neurondm" software package contains the code to transform raw data from the three referenced EBT data sources (Markram et. al. 2015, Paul et. al. 2017 and Allen Cell Types database), but could not identify the raw data source files for this transformation in the manuscript or the linked software "neurondm" on github.

Please provide a figure that shows the workflow how data is extracted from published sources and transformed using the "data model" to an accessible and queryable data source. This workflow should also contain all essential tools.

Further provide a detailed example workflow how new classes are added to the NPO. This has to contain all tools involved and criteria by which new classes are defined.

### Failure of reproducibility.
Given the provided information we could not clearly identify the raw EBT data used for the competency queries and were not able to check whether the results reported where part of the original data.

It seems that the "ttl" files found at the github "NIF-Ontology" "neurons" branch in the https://github.com/SciCrunch/NIF-Ontology/tree/neurons/ttl/generated/neurons directory include the already transformed and created EBT ttl files, but the raw data from which these files were created could not be identified. In general the reported data set is a secondary reference; how can the original data be accessed, verified and referenced? Easy backchecking should be part of the definition in this case to verify any result of a search.

Even tough we invested a reasonable amount of time to setup and try to recreate the database for the reported competency queries, we were not able to recreate them with the information provided from raw data. A description of the transformation of raw CUTs data to an NPO based graph as well as the raw data for EBTs and how to transform this data using "neuromd" was missing, making it impossible to test the queries reported in this manuscript.

### Competency queries
It is unclear whether or not the competency queries are actually valid challenges for the ontology. Since the authors do not show the raw data but only the results of the queries and do not give an expectation of the query results it is impossible to assess their validity.
Provide a table (or any other illustration) that shows the true and false positives as well as the misses in the query results to provide a means to validate the proposed method.

### Data and Code Availability issues
The ontology files, which are at the core of this publication, reside in a side branch of a provided github repository. Since open source projects on platforms like github are by design dynamic, this is a dead link in the making. The core "npo.ttl" file should contain a version number that is also referenced in the paper. Most importantly the full published ontology reported by this manuscript should be provided via its own DOI as well since the content of both the github repository in general and the "neuron" branch in particular will change in the future; the reported status/version should not only be available via a github tag, but also via its own DOI which we have not been able to find in the Data and code availability section.

### Outlook issue
The current examples include data from mammalian cortical sources of three referenced papers. Outline how data from other fields e.g. imaging and other model organisms e.g. invertebrates can be incorporated and which issues the authors are aware of in this respect. This would demonstrate that the approach is not specific to the reported datasets but to the full field of neuroscience as the article is aspiring to. The authors explicitly state that the current paper is a proof-of-concept but they should at least hint at and discuss with other parts of neurosciences they are not covering, or how they should be integrated.

Along these lines give an outlook how this approach should continue; by whom and how will it be expanded; by whom and how should this approach be used in the future; who has stewardship over a potential resulting resource.


## Minor points
- As a general comment, this manuscript has not been sufficiently proofread, making it, besides its demanding content, unnecessarily hard to review. Multiple sections apparently contain redundant wording e.g. page 19 "... phenotypes themselves lend themselves ..." and inconsistent ***tool naming and link presentation schemes (see issues below)***.
As another example the Data and code availability section reads unstructured and needs rephrasing. Paragraphs often read like redundant information since it is not specified for which purpose links in different paragraphs are provided.

- The distinction between Common Usage Types and Evidence Based Types is central to the paper but it should be introduced by providing a more detailed description in Figure 1 A.

- The general approach of modelling a cell type as a "bag of phenotypes" is valid. Fig 2 illustrates the concept, but the link to the actual NPO terms is not described. "Species" or "Brain region" are general terms that can be used to categorize Neuron Phenotypes, but they are not actual NPO terms as the figure caption suggests. Further the relation between Figure 2 and Table 1 is unclear; not all terms in Figure 2 map directly to Table 1 and a further description is not provided in the text.

- Figure 3: predicate "hasExpressionPhenotypeDeterminedByEphysAndPharmacology": two comments: (1) is it wise to combine Ephys and Pharmacology in the same predicate? (2) inconsistency in using "ephys" abbreviated and spelled out in other predicates.

- Page 6, 2nd paragraph: the term "disjointness axioms" falls out of the sky but may not be familiar to people not acquainted with OWL semantics.

- Page 6, bottom paragraph: We could not identify a reference for NeuronLang.

- Inconsistent software naming: "Neuron Lang" and "Neuron DM" are sometimes referenced as "Neuro Lang" or "Neuro DM" e.g. in Figure 4 caption ("Neuro Lang") vs. occurrence in previous issue.

- Page 9, Data and code availability: The section shows link representation consistency. Links are sometimes provided plain in text, sometimes as hidden URLs. Provide links in a consistent, easy to parse manner.

- Page 9, Data and code availability: The text references the NPO as v1.0; the reference points to a github tag containing the tag "npo-1.0" referencing a commit in the `neurons` branch. The file referenced via the provided link to the "npo.ttl" in the neurons branch of this particular tag is identical to the above described file in the `neurons` branch. The linked file does not contain a version number; the only version information available in this file is the entry `owl:versionInfo "2020-08-03" ;`. Users should be easily able to trace back a used file to its origin. Either the file itself should contain the version number as stated in the manuscript, or the github tag name should contain the version info data and the version number in the manuscript should also contain this version information.

- Page 9, Data and code availability: The first paragraph does not specify that the link to the "npo.ttl" file points to a dynamic file and will be updated in the future.

- Page 9, Data and code availability: The description of the link https://raw.githubusercontent.com/SciCrunch/NIF-Ontology/npo-1.0/ttl/npo.ttl does not specify that this is a github tag pointing to the specific v1.0 release and also does not state, that it points to the `neurons` branch; a clarification would help to understand both links only currently point to the exact same file.
